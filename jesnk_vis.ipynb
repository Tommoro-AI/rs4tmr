{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "import robosuite as suite\n",
    "from robosuite.wrappers import GymWrapper\n",
    "\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "\n",
    "def init_env (return_raw_env=False):\n",
    "    rsenv = suite.make(\n",
    "        \"TmrPickPlaceCan\",\n",
    "        robots=\"UR5e\",  # use UR5e robot\n",
    "        use_camera_obs=True,  # use pixel observations\n",
    "        has_offscreen_renderer=True,  # needed if using pixel obs\n",
    "        has_renderer=False,  # make sure we can render to the screen\n",
    "        reward_shaping=True,  # use dense rewards\n",
    "        control_freq=20,  # control should happen fast enough so that simulation looks smooth\n",
    "        camera_depths=True,\n",
    "        camera_names='agentview',\n",
    "    )\n",
    "\n",
    "    # full_observable_list = [\n",
    "    #     'robot0_joint_pos', \n",
    "    #     'robot0_joint_pos_cos', \n",
    "    #     'robot0_joint_pos_sin', \n",
    "    #     'robot0_joint_vel', \n",
    "    #     'robot0_eef_pos', \n",
    "    #     'robot0_eef_quat', \n",
    "    #     'robot0_eef_vel_lin', \n",
    "    #     'robot0_eef_vel_ang', \n",
    "    #     'robot0_gripper_qpos', \n",
    "    #     'robot0_gripper_qvel', \n",
    "    #     'agentview_image', \n",
    "    #     'world_pose_in_gripper', \n",
    "    #     'Milk_pos', \n",
    "    #     'Milk_quat', \n",
    "    #     'Milk_to_robot0_eef_pos', \n",
    "    #     'Milk_to_robot0_eef_quat', \n",
    "    #     'Bread_pos', \n",
    "    #     'Bread_quat', \n",
    "    #     'Bread_to_robot0_eef_pos', \n",
    "    #     'Bread_to_robot0_eef_quat', \n",
    "    #     'Cereal_pos', \n",
    "    #     'Cereal_quat', \n",
    "    #     'Cereal_to_robot0_eef_pos', \n",
    "    #     'Cereal_to_robot0_eef_quat', \n",
    "    #     'Can_pos', \n",
    "    #     'Can_quat', \n",
    "    #     'Can_to_robot0_eef_pos', \n",
    "    #     'Can_to_robot0_eef_quat',\n",
    "    # ]\n",
    "    # for observable in full_observable_list:\n",
    "    #     rsenv.modify_observable(observable, 'enabled', True)\n",
    "    #     rsenv.modify_observable(observable, 'active', True)\n",
    "\n",
    "    useless_observable_list = [\n",
    "        # 'robot0_joint_pos', \n",
    "        # 'robot0_joint_pos_cos', \n",
    "        # 'robot0_joint_pos_sin', \n",
    "        # 'robot0_joint_vel', \n",
    "        # 'robot0_eef_pos', \n",
    "        # 'robot0_eef_quat', \n",
    "        # 'robot0_eef_vel_lin', \n",
    "        # 'robot0_eef_vel_ang', \n",
    "        # 'robot0_gripper_qpos', \n",
    "        # 'robot0_gripper_qvel', \n",
    "        # 'agentview_image', \n",
    "        # 'world_pose_in_gripper', \n",
    "        # 'Milk_pos', \n",
    "        # 'Milk_quat', \n",
    "        # 'Milk_to_robot0_eef_pos', \n",
    "        # 'Milk_to_robot0_eef_quat', \n",
    "        # 'Bread_pos', \n",
    "        # 'Bread_quat', \n",
    "        # 'Bread_to_robot0_eef_pos', \n",
    "        # 'Bread_to_robot0_eef_quat', \n",
    "        # 'Cereal_pos', \n",
    "        # 'Cereal_quat', \n",
    "        # 'Cereal_to_robot0_eef_pos', \n",
    "        # 'Cereal_to_robot0_eef_quat', \n",
    "        # 'Can_pos', \n",
    "        # 'Can_quat', \n",
    "        # 'Can_to_robot0_eef_pos', \n",
    "        # 'Can_to_robot0_eef_quat',\n",
    "    ]\n",
    "    for observable in useless_observable_list:\n",
    "        rsenv.modify_observable(observable, 'enabled', False)\n",
    "        rsenv.modify_observable(observable, 'active', False)\n",
    "\n",
    "    print('Robosuite environment maked:',type(rsenv) , rsenv, dir(rsenv))\n",
    "    print(len(rsenv._observables.keys()))\n",
    "    print(rsenv._observables.keys())\n",
    "\n",
    "    if return_raw_env:\n",
    "        return rsenv\n",
    "    wrapped_env = GymWrapper(\n",
    "        rsenv\n",
    "    )\n",
    "\n",
    "    #env.reset(seed=seed + rank)\n",
    "    wrapped_env.reset()\n",
    "    monitor_env = Monitor(wrapped_env)\n",
    "    #return env\n",
    "    #set_random_seed(seed)\n",
    "    return monitor_env\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robosuite environment maked: <class 'robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan'> <robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan object at 0x7f9f104f2550> ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_action_dim', '_check_grasp', '_check_robot_configuration', '_check_success', '_construct_objects', '_construct_visual_objects', '_create_camera_sensors', '_create_obj_sensors', '_create_segementation_sensor', '_destroy_sim', '_destroy_viewer', '_eef_xmat', '_eef_xpos', '_eef_xquat', '_get_observations', '_get_placement_initializer', '_gripper_to_target', '_initialize_sim', '_input2list', '_load_model', '_load_robots', '_obs_cache', '_observables', '_post_action', '_pre_action', '_reset_internal', '_setup_observables', '_setup_references', '_update_observables', '_visualizations', '_visualize_gripper_to_target', '_xml_processor', 'action_dim', 'action_spec', 'active_observables', 'add_observable', 'bin1_pos', 'bin2_pos', 'bin_size', 'camera_depths', 'camera_heights', 'camera_names', 'camera_segmentations', 'camera_widths', 'check_contact', 'clear_objects', 'close', 'close_renderer', 'control_freq', 'control_timestep', 'cur_time', 'deterministic_reset', 'done', 'edit_model_xml', 'enabled_observables', 'env_configuration', 'get_contacts', 'get_pixel_obs', 'hard_reset', 'has_offscreen_renderer', 'has_renderer', 'horizon', 'ignore_done', 'initialize_renderer', 'initialize_time', 'model', 'model_timestep', 'modify_observable', 'not_in_bin', 'num_cameras', 'num_robots', 'obj_body_id', 'obj_geom_id', 'obj_names', 'obj_to_use', 'object_id', 'object_id_to_sensors', 'object_to_id', 'objects', 'objects_in_bins', 'observation_modalities', 'observation_names', 'observation_spec', 'placement_initializer', 'render', 'render_camera', 'render_collision_mesh', 'render_gpu_device_id', 'render_visual_mesh', 'renderer', 'renderer_config', 'reset', 'reset_from_xml_string', 'reward', 'reward_scale', 'reward_shaping', 'robot_configs', 'robot_names', 'robots', 'set_camera_pos_quat', 'set_xml_processor', 'sim', 'sim_state_initial', 'single_object_mode', 'staged_rewards', 'step', 'table_friction', 'table_full_size', 'target_bin_placements', 'timestep', 'use_camera_obs', 'use_object_obs', 'viewer', 'viewer_get_obs', 'visual_objects', 'visualize', 'z_offset', 'z_rotation']\n",
      "29\n",
      "odict_keys(['robot0_joint_pos', 'robot0_joint_pos_cos', 'robot0_joint_pos_sin', 'robot0_joint_vel', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_eef_vel_lin', 'robot0_eef_vel_ang', 'robot0_gripper_qpos', 'robot0_gripper_qvel', 'agentview_image', 'agentview_depth', 'world_pose_in_gripper', 'Milk_pos', 'Milk_quat', 'Milk_to_robot0_eef_pos', 'Milk_to_robot0_eef_quat', 'Bread_pos', 'Bread_quat', 'Bread_to_robot0_eef_pos', 'Bread_to_robot0_eef_quat', 'Cereal_pos', 'Cereal_quat', 'Cereal_to_robot0_eef_pos', 'Cereal_to_robot0_eef_quat', 'Can_pos', 'Can_quat', 'Can_to_robot0_eef_pos', 'Can_to_robot0_eef_quat'])\n"
     ]
    }
   ],
   "source": [
    "import mediapy as media\n",
    "env = init_env(return_raw_env=True)\n",
    "#env.modify_observable('agentview_depth', 'enabled', False)\n",
    "#env.modify_observable('agentview_depth', 'active', False)\n",
    "#media.show_image(obs['agentview_image'][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['robot0_joint_pos_cos', 'robot0_joint_pos_sin', 'robot0_joint_vel', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos', 'robot0_gripper_qvel', 'agentview_image', 'agentview_depth', 'Can_pos', 'Can_quat', 'Can_to_robot0_eef_pos', 'Can_to_robot0_eef_quat', 'robot0_proprio-state', 'object-state'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs.keys()\n",
    "\n",
    "# Depth is already. but how can merge this with DummyVecEnv, GymWrapper, Monitor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making env\n",
      "Robosuite environment maked: <class 'robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan'> <robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan object at 0x7fef0bea9ca0> ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_action_dim', '_check_grasp', '_check_robot_configuration', '_check_success', '_construct_objects', '_construct_visual_objects', '_create_camera_sensors', '_create_obj_sensors', '_create_segementation_sensor', '_destroy_sim', '_destroy_viewer', '_eef_xmat', '_eef_xpos', '_eef_xquat', '_get_observations', '_get_placement_initializer', '_gripper_to_target', '_initialize_sim', '_input2list', '_load_model', '_load_robots', '_obs_cache', '_observables', '_post_action', '_pre_action', '_reset_internal', '_setup_observables', '_setup_references', '_update_observables', '_visualizations', '_visualize_gripper_to_target', '_xml_processor', 'action_dim', 'action_spec', 'active_observables', 'add_observable', 'bin1_pos', 'bin2_pos', 'bin_size', 'camera_depths', 'camera_heights', 'camera_names', 'camera_segmentations', 'camera_widths', 'check_contact', 'clear_objects', 'close', 'close_renderer', 'control_freq', 'control_timestep', 'cur_time', 'deterministic_reset', 'done', 'edit_model_xml', 'enabled_observables', 'env_configuration', 'get_contacts', 'get_pixel_obs', 'hard_reset', 'has_offscreen_renderer', 'has_renderer', 'horizon', 'ignore_done', 'initialize_renderer', 'initialize_time', 'model', 'model_timestep', 'modify_observable', 'not_in_bin', 'num_cameras', 'num_robots', 'obj_body_id', 'obj_geom_id', 'obj_names', 'obj_to_use', 'object_id', 'object_id_to_sensors', 'object_to_id', 'objects', 'objects_in_bins', 'observation_modalities', 'observation_names', 'observation_spec', 'placement_initializer', 'render', 'render_camera', 'render_collision_mesh', 'render_gpu_device_id', 'render_visual_mesh', 'renderer', 'renderer_config', 'reset', 'reset_from_xml_string', 'reward', 'reward_scale', 'reward_shaping', 'robot_configs', 'robot_names', 'robots', 'set_camera_pos_quat', 'set_xml_processor', 'sim', 'sim_state_initial', 'single_object_mode', 'staged_rewards', 'step', 'table_friction', 'table_full_size', 'target_bin_placements', 'timestep', 'use_camera_obs', 'use_object_obs', 'viewer', 'viewer_get_obs', 'visual_objects', 'visualize', 'z_offset', 'z_rotation']\n",
      "27\n",
      "odict_keys(['robot0_joint_pos', 'robot0_joint_pos_cos', 'robot0_joint_pos_sin', 'robot0_joint_vel', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_eef_vel_lin', 'robot0_eef_vel_ang', 'robot0_gripper_qpos', 'robot0_gripper_qvel', 'world_pose_in_gripper', 'Milk_pos', 'Milk_quat', 'Milk_to_robot0_eef_pos', 'Milk_to_robot0_eef_quat', 'Bread_pos', 'Bread_quat', 'Bread_to_robot0_eef_pos', 'Bread_to_robot0_eef_quat', 'Cereal_pos', 'Cereal_quat', 'Cereal_to_robot0_eef_pos', 'Cereal_to_robot0_eef_quat', 'Can_pos', 'Can_quat', 'Can_to_robot0_eef_pos', 'Can_to_robot0_eef_quat'])\n",
      "load model\n",
      "reset env\n",
      "_observables: \n",
      "robot0_joint_pos <robosuite.utils.observables.Observable object at 0x7fef302ba1c0>\n",
      "robot0_joint_pos_cos <robosuite.utils.observables.Observable object at 0x7fef302baeb0>\n",
      "robot0_joint_pos_sin <robosuite.utils.observables.Observable object at 0x7fef302bae20>\n",
      "robot0_joint_vel <robosuite.utils.observables.Observable object at 0x7fef302ba640>\n",
      "robot0_eef_pos <robosuite.utils.observables.Observable object at 0x7fef302ba2e0>\n",
      "robot0_eef_quat <robosuite.utils.observables.Observable object at 0x7fef302ba040>\n",
      "robot0_eef_vel_lin <robosuite.utils.observables.Observable object at 0x7fef302babe0>\n",
      "robot0_eef_vel_ang <robosuite.utils.observables.Observable object at 0x7fef302bac40>\n",
      "robot0_gripper_qpos <robosuite.utils.observables.Observable object at 0x7fef302baf70>\n",
      "robot0_gripper_qvel <robosuite.utils.observables.Observable object at 0x7fef302ba250>\n",
      "world_pose_in_gripper <robosuite.utils.observables.Observable object at 0x7fef302bab50>\n",
      "Milk_pos <robosuite.utils.observables.Observable object at 0x7fef302bad30>\n",
      "Milk_quat <robosuite.utils.observables.Observable object at 0x7fef44350130>\n",
      "Milk_to_robot0_eef_pos <robosuite.utils.observables.Observable object at 0x7fef44350550>\n",
      "Milk_to_robot0_eef_quat <robosuite.utils.observables.Observable object at 0x7fef44350cd0>\n",
      "Bread_pos <robosuite.utils.observables.Observable object at 0x7fef0bb77130>\n",
      "Bread_quat <robosuite.utils.observables.Observable object at 0x7fef0bb770d0>\n",
      "Bread_to_robot0_eef_pos <robosuite.utils.observables.Observable object at 0x7fef44482100>\n",
      "Bread_to_robot0_eef_quat <robosuite.utils.observables.Observable object at 0x7fef0baa90d0>\n",
      "Cereal_pos <robosuite.utils.observables.Observable object at 0x7fef0baa93d0>\n",
      "Cereal_quat <robosuite.utils.observables.Observable object at 0x7fef0baa9af0>\n",
      "Cereal_to_robot0_eef_pos <robosuite.utils.observables.Observable object at 0x7fef0baa9910>\n",
      "Cereal_to_robot0_eef_quat <robosuite.utils.observables.Observable object at 0x7fef0baa95b0>\n",
      "Can_pos <robosuite.utils.observables.Observable object at 0x7fef0baa9280>\n",
      "Can_quat <robosuite.utils.observables.Observable object at 0x7fef0baa9400>\n",
      "Can_to_robot0_eef_pos <robosuite.utils.observables.Observable object at 0x7fef0baa99d0>\n",
      "Can_to_robot0_eef_quat <robosuite.utils.observables.Observable object at 0x7fef0baa9040>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No \"camera\" with name frontview_depth exists. Available \"camera\" names = ('frontview', 'birdview', 'agentview', 'robot0_robotview', 'robot0_eye_in_hand').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m obs, rewards, dones, info \u001b[38;5;241m=\u001b[39m vec_env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#print(t, len(obs), obs)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#print('rendering env')\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m rendered_array\u001b[38;5;241m=\u001b[39m\u001b[43mvec_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m480\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfrontview_depth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 'frontview', 'birdview', 'agentview', 'robot0_robotview', 'robot0_eye_in_hand')\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# revese the image with respect to x-axis\u001b[39;00m\n\u001b[1;32m     39\u001b[0m rendered_array \u001b[38;5;241m=\u001b[39m rendered_array[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :, :]\n",
      "File \u001b[0;32m/research/rs4tmr/robosuite/utils/binding_utils.py:1123\u001b[0m, in \u001b[0;36mMjSim.render\u001b[0;34m(self, width, height, camera_name, depth, mode, device_id, segmentation)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     camera_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     camera_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera_name2id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcamera_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffscreen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly offscreen supported for now\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_context_offscreen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/research/rs4tmr/robosuite/utils/binding_utils.py:429\u001b[0m, in \u001b[0;36mMjModel.camera_name2id\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get camera id from  camera name.\"\"\"\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_camera_name2id:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m exists. Available \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m names = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera_names)\n\u001b[1;32m    431\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_camera_name2id[name]\n",
      "\u001b[0;31mValueError\u001b[0m: No \"camera\" with name frontview_depth exists. Available \"camera\" names = ('frontview', 'birdview', 'agentview', 'robot0_robotview', 'robot0_eye_in_hand')."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "\n",
    "#from my_utils import make_env\n",
    "import mediapy as media\n",
    "\n",
    "\n",
    "env_id = 'TmrPickPlaceCan'\n",
    "horizon = 50\n",
    "frames = []\n",
    "\n",
    "print('making env')\n",
    "vec_env = DummyVecEnv([init_env])\n",
    "\n",
    "print('load model')\n",
    "model = SAC.load(env_id, env=vec_env)\n",
    "\n",
    "print('reset env')\n",
    "obs = vec_env.reset()\n",
    "\n",
    "print('_observables: ')\n",
    "for key, val in vec_env.envs[0].env.env._observables.items():\n",
    "    print(key, val)\n",
    "    pass\n",
    "for t in range(horizon):\n",
    "    #print('predict by model')\n",
    "    action, _states = model.predict(obs)\n",
    "\n",
    "    #print('step forward')\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    #print(t, len(obs), obs)\n",
    "    \n",
    "    #print('rendering env')\n",
    "    rendered_array=vec_env.envs[0].sim.render(width=640, height=480, camera_name='frontview', device_id=0) # 'frontview', 'birdview', 'agentview', 'robot0_robotview', 'robot0_eye_in_hand')\n",
    "    # revese the image with respect to x-axis\n",
    "    rendered_array = rendered_array[::-1, :, :]\n",
    "    \n",
    "    frames.append(rendered_array)\n",
    "media.show_video(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 51)\n"
     ]
    }
   ],
   "source": [
    "obs = vec_env.reset()\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /research/rs4tmr/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robosuite environment maked: <class 'robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan'> <robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan object at 0x7ff04aaedeb0> ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_action_dim', '_check_grasp', '_check_robot_configuration', '_check_success', '_construct_objects', '_construct_visual_objects', '_create_camera_sensors', '_create_obj_sensors', '_create_segementation_sensor', '_destroy_sim', '_destroy_viewer', '_eef_xmat', '_eef_xpos', '_eef_xquat', '_get_observations', '_get_placement_initializer', '_gripper_to_target', '_initialize_sim', '_input2list', '_load_model', '_load_robots', '_obs_cache', '_observables', '_post_action', '_pre_action', '_reset_internal', '_setup_observables', '_setup_references', '_update_observables', '_visualizations', '_visualize_gripper_to_target', '_xml_processor', 'action_dim', 'action_spec', 'active_observables', 'add_observable', 'bin1_pos', 'bin2_pos', 'bin_size', 'camera_depths', 'camera_heights', 'camera_names', 'camera_segmentations', 'camera_widths', 'check_contact', 'clear_objects', 'close', 'close_renderer', 'control_freq', 'control_timestep', 'cur_time', 'deterministic_reset', 'done', 'edit_model_xml', 'enabled_observables', 'env_configuration', 'get_contacts', 'get_pixel_obs', 'hard_reset', 'has_offscreen_renderer', 'has_renderer', 'horizon', 'ignore_done', 'initialize_renderer', 'initialize_time', 'model', 'model_timestep', 'modify_observable', 'not_in_bin', 'num_cameras', 'num_robots', 'obj_body_id', 'obj_geom_id', 'obj_names', 'obj_to_use', 'object_id', 'object_id_to_sensors', 'object_to_id', 'objects', 'objects_in_bins', 'observation_modalities', 'observation_names', 'observation_spec', 'placement_initializer', 'render', 'render_camera', 'render_collision_mesh', 'render_gpu_device_id', 'render_visual_mesh', 'renderer', 'renderer_config', 'reset', 'reset_from_xml_string', 'reward', 'reward_scale', 'reward_shaping', 'robot_configs', 'robot_names', 'robots', 'set_camera_pos_quat', 'set_xml_processor', 'sim', 'sim_state_initial', 'single_object_mode', 'staged_rewards', 'step', 'table_friction', 'table_full_size', 'target_bin_placements', 'timestep', 'use_camera_obs', 'use_object_obs', 'viewer', 'viewer_get_obs', 'visual_objects', 'visualize', 'z_offset', 'z_rotation']\n",
      "27\n",
      "odict_keys(['robot0_joint_pos', 'robot0_joint_pos_cos', 'robot0_joint_pos_sin', 'robot0_joint_vel', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_eef_vel_lin', 'robot0_eef_vel_ang', 'robot0_gripper_qpos', 'robot0_gripper_qvel', 'world_pose_in_gripper', 'Milk_pos', 'Milk_quat', 'Milk_to_robot0_eef_pos', 'Milk_to_robot0_eef_quat', 'Bread_pos', 'Bread_quat', 'Bread_to_robot0_eef_pos', 'Bread_to_robot0_eef_quat', 'Cereal_pos', 'Cereal_quat', 'Cereal_to_robot0_eef_pos', 'Cereal_to_robot0_eef_quat', 'Can_pos', 'Can_quat', 'Can_to_robot0_eef_pos', 'Can_to_robot0_eef_quat'])\n"
     ]
    }
   ],
   "source": [
    "import robosuite as suite\n",
    "from robosuite.wrappers import GymWrapper\n",
    "\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "\n",
    "rsenv = suite.make(\n",
    "    \"TmrPickPlaceCan\",\n",
    "    robots=\"UR5e\",  # use UR5e robot\n",
    "    use_camera_obs=False,  # use pixel observations\n",
    "    has_offscreen_renderer=True,  # needed if using pixel obs\n",
    "    has_renderer=True,  # make sure we can render to the screen\n",
    "    reward_shaping=True,  # use dense rewards\n",
    "    control_freq=20,  # control should happen fast enough so that simulation looks smooth\n",
    ")\n",
    "\n",
    "# full_observable_list = [\n",
    "#     'robot0_joint_pos', \n",
    "#     'robot0_joint_pos_cos', \n",
    "#     'robot0_joint_pos_sin', \n",
    "#     'robot0_joint_vel', \n",
    "#     'robot0_eef_pos', \n",
    "#     'robot0_eef_quat', \n",
    "#     'robot0_eef_vel_lin', \n",
    "#     'robot0_eef_vel_ang', \n",
    "#     'robot0_gripper_qpos', \n",
    "#     'robot0_gripper_qvel', \n",
    "#     'agentview_image', \n",
    "#     'world_pose_in_gripper', \n",
    "#     'Milk_pos', \n",
    "#     'Milk_quat', \n",
    "#     'Milk_to_robot0_eef_pos', \n",
    "#     'Milk_to_robot0_eef_quat', \n",
    "#     'Bread_pos', \n",
    "#     'Bread_quat', \n",
    "#     'Bread_to_robot0_eef_pos', \n",
    "#     'Bread_to_robot0_eef_quat', \n",
    "#     'Cereal_pos', \n",
    "#     'Cereal_quat', \n",
    "#     'Cereal_to_robot0_eef_pos', \n",
    "#     'Cereal_to_robot0_eef_quat', \n",
    "#     'Can_pos', \n",
    "#     'Can_quat', \n",
    "#     'Can_to_robot0_eef_pos', \n",
    "#     'Can_to_robot0_eef_quat',\n",
    "# ]\n",
    "# for observable in full_observable_list:\n",
    "#     rsenv.modify_observable(observable, 'enabled', True)\n",
    "#     rsenv.modify_observable(observable, 'active', True)\n",
    "\n",
    "useless_observable_list = [\n",
    "    # 'robot0_joint_pos', \n",
    "    # 'robot0_joint_pos_cos', \n",
    "    # 'robot0_joint_pos_sin', \n",
    "    # 'robot0_joint_vel', \n",
    "    # 'robot0_eef_pos', \n",
    "    # 'robot0_eef_quat', \n",
    "    # 'robot0_eef_vel_lin', \n",
    "    # 'robot0_eef_vel_ang', \n",
    "    # 'robot0_gripper_qpos', \n",
    "    # 'robot0_gripper_qvel', \n",
    "    # 'agentview_image', \n",
    "    # 'world_pose_in_gripper', \n",
    "    # 'Milk_pos', \n",
    "    # 'Milk_quat', \n",
    "    # 'Milk_to_robot0_eef_pos', \n",
    "    # 'Milk_to_robot0_eef_quat', \n",
    "    # 'Bread_pos', \n",
    "    # 'Bread_quat', \n",
    "    # 'Bread_to_robot0_eef_pos', \n",
    "    # 'Bread_to_robot0_eef_quat', \n",
    "    # 'Cereal_pos', \n",
    "    # 'Cereal_quat', \n",
    "    # 'Cereal_to_robot0_eef_pos', \n",
    "    # 'Cereal_to_robot0_eef_quat', \n",
    "    # 'Can_pos', \n",
    "    # 'Can_quat', \n",
    "    # 'Can_to_robot0_eef_pos', \n",
    "    # 'Can_to_robot0_eef_quat',\n",
    "]\n",
    "for observable in useless_observable_list:\n",
    "    rsenv.modify_observable(observable, 'enabled', False)\n",
    "    rsenv.modify_observable(observable, 'active', False)\n",
    "\n",
    "print('Robosuite environment maked:',type(rsenv) , rsenv, dir(rsenv))\n",
    "print(len(rsenv._observables.keys()))\n",
    "print(rsenv._observables.keys())\n",
    "\n",
    "env = GymWrapper(\n",
    "    rsenv\n",
    ")\n",
    "\n",
    "env.reset(seed=0)\n",
    "\n",
    "new_env = Monitor(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[164, 155, 147],\n",
       "        [162, 153, 145],\n",
       "        [163, 154, 146],\n",
       "        ...,\n",
       "        [179, 170, 163],\n",
       "        [163, 154, 146],\n",
       "        [181, 172, 164]],\n",
       "\n",
       "       [[165, 156, 149],\n",
       "        [163, 154, 146],\n",
       "        [162, 153, 145],\n",
       "        ...,\n",
       "        [163, 155, 146],\n",
       "        [177, 169, 160],\n",
       "        [197, 188, 179]],\n",
       "\n",
       "       [[167, 158, 151],\n",
       "        [165, 156, 148],\n",
       "        [163, 154, 146],\n",
       "        ...,\n",
       "        [185, 177, 168],\n",
       "        [192, 183, 174],\n",
       "        [189, 180, 171]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[129, 127, 123],\n",
       "        [129, 127, 123],\n",
       "        [129, 128, 124],\n",
       "        ...,\n",
       "        [ 86,  85,  82],\n",
       "        [ 85,  84,  82],\n",
       "        [ 86,  84,  82]],\n",
       "\n",
       "       [[129, 128, 124],\n",
       "        [129, 127, 123],\n",
       "        [128, 127, 122],\n",
       "        ...,\n",
       "        [ 85,  84,  81],\n",
       "        [ 85,  84,  81],\n",
       "        [ 86,  85,  82]],\n",
       "\n",
       "       [[128, 126, 121],\n",
       "        [128, 125, 120],\n",
       "        [127, 124, 120],\n",
       "        ...,\n",
       "        [ 84,  82,  79],\n",
       "        [ 85,  83,  80],\n",
       "        [ 85,  84,  81]]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsenv = suite.make(\n",
    "    \"TmrPickPlaceCan\",\n",
    "    robots=\"UR5e\",  # use UR5e robot\n",
    "    use_camera_obs=False,  # use pixel observations\n",
    "    has_offscreen_renderer=True,  # needed if using pixel obs\n",
    "    has_renderer=True,  # make sure we can render to the screen\n",
    "    reward_shaping=True,  # use dense rewards\n",
    "    control_freq=20,  # control should happen fast enough so that simulation looks smooth\n",
    ")\n",
    "rsenv.sim.render(width=640, height=480, camera_name='frontview', device_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(new_env.render())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs4tmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
