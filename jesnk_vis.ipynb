{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /research/rs4tmr/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robosuite environment maked: <class 'robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan'> <robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan object at 0x7f147cf821f0> ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_action_dim', '_check_grasp', '_check_robot_configuration', '_check_success', '_construct_objects', '_construct_visual_objects', '_create_camera_sensors', '_create_obj_sensors', '_create_segementation_sensor', '_destroy_sim', '_destroy_viewer', '_eef_xmat', '_eef_xpos', '_eef_xquat', '_get_observations', '_get_placement_initializer', '_gripper_to_target', '_initialize_sim', '_input2list', '_load_model', '_load_robots', '_obs_cache', '_observables', '_post_action', '_pre_action', '_reset_internal', '_setup_observables', '_setup_references', '_update_observables', '_visualizations', '_visualize_gripper_to_target', '_xml_processor', 'action_dim', 'action_spec', 'active_observables', 'add_observable', 'bin1_pos', 'bin2_pos', 'bin_size', 'camera_depths', 'camera_heights', 'camera_names', 'camera_segmentations', 'camera_widths', 'check_contact', 'clear_objects', 'close', 'close_renderer', 'control_freq', 'control_timestep', 'cur_time', 'deterministic_reset', 'done', 'edit_model_xml', 'enabled_observables', 'env_configuration', 'get_contacts', 'get_pixel_obs', 'hard_reset', 'has_offscreen_renderer', 'has_renderer', 'horizon', 'ignore_done', 'image_states', 'initialize_renderer', 'initialize_time', 'model', 'model_timestep', 'modify_observable', 'not_in_bin', 'num_cameras', 'num_robots', 'obj_body_id', 'obj_geom_id', 'obj_names', 'obj_to_use', 'object_id', 'object_id_to_sensors', 'object_to_id', 'objects', 'objects_in_bins', 'observation_modalities', 'observation_names', 'observation_spec', 'placement_initializer', 'render', 'render_camera', 'render_collision_mesh', 'render_gpu_device_id', 'render_visual_mesh', 'renderer', 'renderer_config', 'reset', 'reset_from_xml_string', 'reward', 'reward_scale', 'reward_shaping', 'robot_configs', 'robot_names', 'robots', 'set_camera_pos_quat', 'set_xml_processor', 'sim', 'sim_state_initial', 'single_object_mode', 'staged_rewards', 'step', 'table_friction', 'table_full_size', 'target_bin_placements', 'timestep', 'use_camera_obs', 'use_object_obs', 'viewer', 'viewer_get_obs', 'visual_objects', 'visualize', 'z_offset', 'z_rotation']\n",
      "29\n",
      "Key: robot0_joint_pos_cos, size: 6\n",
      "Key: robot0_joint_pos_sin, size: 6\n",
      "Key: robot0_joint_vel, size: 6\n",
      "Key: robot0_eef_pos, size: 3\n",
      "Key: robot0_eef_quat, size: 4\n",
      "Key: robot0_gripper_qpos, size: 6\n",
      "Key: robot0_gripper_qvel, size: 6\n",
      "Key: Can_pos, size: 3\n",
      "Key: Can_quat, size: 4\n",
      "Key: Can_to_robot0_eef_pos, size: 3\n",
      "Key: Can_to_robot0_eef_quat, size: 4\n",
      "Key: robot0_proprio-state, size: 37\n",
      "Key: object-state, size: 14\n",
      "Total observation size: 102\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'agentview_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_env\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmedia\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43minit_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/research/rs4tmr/my_utils.py:165\u001b[0m, in \u001b[0;36minit_env\u001b[0;34m(return_raw_env)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Monitor(rsenv)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m#obs_inspector = ObservationInspector(rsenv)\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m wrapped_env \u001b[38;5;241m=\u001b[39m \u001b[43mGymWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrsenv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#keys\u001b[39;49;00m\n\u001b[1;32m    168\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m#env.reset(seed=seed + rank)\u001b[39;00m\n\u001b[1;32m    171\u001b[0m wrapped_env\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m/research/rs4tmr/robosuite/wrappers/gym_wrapper.py:63\u001b[0m, in \u001b[0;36mGymWrapper.__init__\u001b[0;34m(self, env, keys)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# set up observation and action spaces\u001b[39;00m\n\u001b[1;32m     62\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodality_dims \u001b[38;5;241m=\u001b[39m {key: obs[key]\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morigin_keys}\n\u001b[1;32m     64\u001b[0m flat_ob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_obs(obs)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_dim \u001b[38;5;241m=\u001b[39m flat_ob\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[0;32m/research/rs4tmr/robosuite/wrappers/gym_wrapper.py:63\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# set up observation and action spaces\u001b[39;00m\n\u001b[1;32m     62\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodality_dims \u001b[38;5;241m=\u001b[39m {key: \u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morigin_keys}\n\u001b[1;32m     64\u001b[0m flat_ob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_obs(obs)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_dim \u001b[38;5;241m=\u001b[39m flat_ob\u001b[38;5;241m.\u001b[39msize\n",
      "\u001b[0;31mKeyError\u001b[0m: 'agentview_image'"
     ]
    }
   ],
   "source": [
    "from my_utils import init_env\n",
    "import mediapy as media\n",
    "env = init_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Setup\n",
      "odict_keys(['robot0_joint_pos_cos', 'robot0_joint_pos_sin', 'robot0_joint_vel', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos', 'robot0_gripper_qvel', 'Can_pos', 'Can_quat', 'Can_to_robot0_eef_pos', 'Can_to_robot0_eef_quat', 'robot0_proprio-state', 'object-state'])\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "print(obs[0].shape)\n",
    "#env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/rs4tmr/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.image_states to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.image_states` for environment variables or `env.get_wrapper_attr('image_states')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'agentview_image': array([[[203, 190, 182],\n",
       "         [211, 198, 189],\n",
       "         [208, 196, 185],\n",
       "         ...,\n",
       "         [186, 177, 168],\n",
       "         [191, 182, 173],\n",
       "         [187, 178, 169]],\n",
       " \n",
       "        [[203, 190, 182],\n",
       "         [208, 195, 186],\n",
       "         [210, 197, 187],\n",
       "         ...,\n",
       "         [191, 182, 173],\n",
       "         [193, 184, 175],\n",
       "         [179, 170, 161]],\n",
       " \n",
       "        [[205, 193, 185],\n",
       "         [205, 192, 184],\n",
       "         [208, 195, 186],\n",
       "         ...,\n",
       "         [203, 195, 186],\n",
       "         [191, 183, 174],\n",
       "         [184, 175, 166]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[117, 115, 111],\n",
       "         [118, 116, 112],\n",
       "         [118, 116, 112],\n",
       "         ...,\n",
       "         [117, 115, 111],\n",
       "         [117, 115, 111],\n",
       "         [116, 114, 111]],\n",
       " \n",
       "        [[118, 117, 113],\n",
       "         [118, 116, 113],\n",
       "         [118, 116, 113],\n",
       "         ...,\n",
       "         [118, 116, 112],\n",
       "         [117, 116, 112],\n",
       "         [117, 115, 112]],\n",
       " \n",
       "        [[118, 116, 113],\n",
       "         [118, 116, 112],\n",
       "         [117, 115, 112],\n",
       "         ...,\n",
       "         [118, 116, 113],\n",
       "         [117, 115, 112],\n",
       "         [117, 115, 112]]], dtype=uint8),\n",
       " 'agentview_depth': array([[[0.9939623 ],\n",
       "         [0.9939623 ],\n",
       "         [0.9939623 ],\n",
       "         ...,\n",
       "         [0.9939623 ],\n",
       "         [0.9939623 ],\n",
       "         [0.9939623 ]],\n",
       " \n",
       "        [[0.9939762 ],\n",
       "         [0.9939762 ],\n",
       "         [0.9939762 ],\n",
       "         ...,\n",
       "         [0.9939762 ],\n",
       "         [0.9939762 ],\n",
       "         [0.9939762 ]],\n",
       " \n",
       "        [[0.99399006],\n",
       "         [0.99399006],\n",
       "         [0.99399006],\n",
       "         ...,\n",
       "         [0.99399006],\n",
       "         [0.99399006],\n",
       "         [0.99399006]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.99649286],\n",
       "         [0.99649286],\n",
       "         [0.99649286],\n",
       "         ...,\n",
       "         [0.99649286],\n",
       "         [0.99649286],\n",
       "         [0.99649286]],\n",
       " \n",
       "        [[0.99648476],\n",
       "         [0.99648476],\n",
       "         [0.99648476],\n",
       "         ...,\n",
       "         [0.99648476],\n",
       "         [0.99648476],\n",
       "         [0.99648476]],\n",
       " \n",
       "        [[0.99647665],\n",
       "         [0.99647665],\n",
       "         [0.99647665],\n",
       "         ...,\n",
       "         [0.99647665],\n",
       "         [0.99647665],\n",
       "         [0.99647665]]], dtype=float32)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.image_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get observation according key name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/rs4tmr/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_obs_according_to_key to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_obs_according_to_key` for environment variables or `env.get_wrapper_attr('get_obs_according_to_key')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.89218116, -0.19680942, -0.77927584, -0.66216597, -0.02516486,\n",
       "       -0.41917018])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "obs = env.step(env.action_space.sample())\n",
    "env.get_obs_according_to_key(obs[0],'robot0_joint_pos_cos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Checkpoint load and Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /research/rs4tmr/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making env\n",
      "Initalized env with init_env\n",
      "Selected observables: ['robot0_joint_pos', 'robot0_joint_vel', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_eef_vel_lin', 'robot0_eef_vel_ang', 'robot0_gripper_qpos', 'robot0_gripper_qvel', 'Can_to_robot0_eef_pos', 'Can_to_robot0_eef_quat']\n",
      "Robosuite environment maked: <class 'robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan'> <robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan object at 0x7f996b54d0d0> ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_action_dim', '_check_grasp', '_check_robot_configuration', '_check_success', '_construct_objects', '_construct_visual_objects', '_create_camera_sensors', '_create_obj_sensors', '_create_segementation_sensor', '_destroy_sim', '_destroy_viewer', '_eef_xmat', '_eef_xpos', '_eef_xquat', '_get_observations', '_get_placement_initializer', '_get_placement_initializer_origin', '_gripper_to_target', '_initialize_sim', '_input2list', '_load_model', '_load_robots', '_obs_cache', '_observables', '_post_action', '_pre_action', '_reset_internal', '_setup_observables', '_setup_references', '_update_observables', '_visualizations', '_visualize_gripper_to_target', '_xml_processor', 'action_dim', 'action_spec', 'active_observables', 'add_observable', 'bin1_pos', 'bin2_pos', 'bin_size', 'camera_depths', 'camera_heights', 'camera_names', 'camera_segmentations', 'camera_widths', 'check_contact', 'clear_objects', 'close', 'close_renderer', 'control_freq', 'control_timestep', 'cur_time', 'deterministic_reset', 'done', 'edit_model_xml', 'enabled_observables', 'env_configuration', 'get_contacts', 'get_pixel_obs', 'hard_reset', 'has_offscreen_renderer', 'has_renderer', 'horizon', 'ignore_done', 'image_states', 'initialize_renderer', 'initialize_time', 'model', 'model_timestep', 'modify_observable', 'not_in_bin', 'num_cameras', 'num_robots', 'obj_body_id', 'obj_geom_id', 'obj_names', 'obj_to_use', 'object_id', 'object_id_to_sensors', 'object_to_id', 'objects', 'objects_in_bins', 'observation_modalities', 'observation_names', 'observation_spec', 'placement_initializer', 'render', 'render_camera', 'render_collision_mesh', 'render_gpu_device_id', 'render_visual_mesh', 'renderer', 'renderer_config', 'reset', 'reset_from_xml_string', 'reward', 'reward_scale', 'reward_shaping', 'robot_configs', 'robot_names', 'robots', 'set_camera_pos_quat', 'set_xml_processor', 'sim', 'sim_state_initial', 'single_object_mode', 'staged_rewards', 'step', 'table_friction', 'table_full_size', 'target_bin_placements', 'timestep', 'use_camera_obs', 'use_object_obs', 'viewer', 'viewer_get_obs', 'visual_objects', 'visualize', 'z_offset', 'z_rotation']\n",
      "29\n",
      "### Observation keys ###\n",
      "Key: robot0_joint_pos, size: 6\n",
      "Key: robot0_joint_vel, size: 6\n",
      "Key: robot0_eef_pos, size: 3\n",
      "Key: robot0_eef_quat, size: 4\n",
      "Key: robot0_eef_vel_lin, size: 3\n",
      "Key: robot0_eef_vel_ang, size: 3\n",
      "Key: robot0_gripper_qpos, size: 6\n",
      "Key: robot0_gripper_qvel, size: 6\n",
      "Key: Can_pos, size: 3\n",
      "Key: Can_quat, size: 4\n",
      "Key: Can_to_robot0_eef_pos, size: 3\n",
      "Key: Can_to_robot0_eef_quat, size: 4\n",
      "Key: robot0_proprio-state, size: 37\n",
      "Key: object-state, size: 14\n",
      "Total observation size: 102\n",
      "########################\n",
      "load model\n",
      "reset env\n",
      "_observables: \n",
      "robot0_joint_pos <robosuite.utils.observables.Observable object at 0x7f984da396d0>\n",
      "robot0_joint_pos_cos <robosuite.utils.observables.Observable object at 0x7f984da39700>\n",
      "robot0_joint_pos_sin <robosuite.utils.observables.Observable object at 0x7f984da39730>\n",
      "robot0_joint_vel <robosuite.utils.observables.Observable object at 0x7f984da39790>\n",
      "robot0_eef_pos <robosuite.utils.observables.Observable object at 0x7f984da39970>\n",
      "robot0_eef_quat <robosuite.utils.observables.Observable object at 0x7f984da399a0>\n",
      "robot0_eef_vel_lin <robosuite.utils.observables.Observable object at 0x7f984da399d0>\n",
      "robot0_eef_vel_ang <robosuite.utils.observables.Observable object at 0x7f984da39a00>\n",
      "robot0_gripper_qpos <robosuite.utils.observables.Observable object at 0x7f984da39a60>\n",
      "robot0_gripper_qvel <robosuite.utils.observables.Observable object at 0x7f984da39ac0>\n",
      "agentview_image <robosuite.utils.observables.Observable object at 0x7f984da39910>\n",
      "agentview_depth <robosuite.utils.observables.Observable object at 0x7f984da39940>\n",
      "world_pose_in_gripper <robosuite.utils.observables.Observable object at 0x7f984da3f040>\n",
      "Milk_pos <robosuite.utils.observables.Observable object at 0x7f984da3f070>\n",
      "Milk_quat <robosuite.utils.observables.Observable object at 0x7f984da3f0a0>\n",
      "Milk_to_robot0_eef_pos <robosuite.utils.observables.Observable object at 0x7f984da3f0d0>\n",
      "Milk_to_robot0_eef_quat <robosuite.utils.observables.Observable object at 0x7f984da3f100>\n",
      "Bread_pos <robosuite.utils.observables.Observable object at 0x7f984da3f190>\n",
      "Bread_quat <robosuite.utils.observables.Observable object at 0x7f984da3f1f0>\n",
      "Bread_to_robot0_eef_pos <robosuite.utils.observables.Observable object at 0x7f984da3f250>\n",
      "Bread_to_robot0_eef_quat <robosuite.utils.observables.Observable object at 0x7f984da3f280>\n",
      "Cereal_pos <robosuite.utils.observables.Observable object at 0x7f984da3f310>\n",
      "Cereal_quat <robosuite.utils.observables.Observable object at 0x7f984da3f370>\n",
      "Cereal_to_robot0_eef_pos <robosuite.utils.observables.Observable object at 0x7f984da3f3d0>\n",
      "Cereal_to_robot0_eef_quat <robosuite.utils.observables.Observable object at 0x7f984da3f400>\n",
      "Can_pos <robosuite.utils.observables.Observable object at 0x7f984da3f490>\n",
      "Can_quat <robosuite.utils.observables.Observable object at 0x7f984da3f4f0>\n",
      "Can_to_robot0_eef_pos <robosuite.utils.observables.Observable object at 0x7f984da3f550>\n",
      "Can_to_robot0_eef_quat <robosuite.utils.observables.Observable object at 0x7f984da3f580>\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#print('step forward')\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m obs, rewards, dones, info \u001b[38;5;241m=\u001b[39m \u001b[43mvec_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#print(t, len(obs), obs)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#print('rendering env')\u001b[39;00m\n\u001b[1;32m     38\u001b[0m rendered_array\u001b[38;5;241m=\u001b[39mvec_env\u001b[38;5;241m.\u001b[39menvs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mrender(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m480\u001b[39m, camera_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrontview\u001b[39m\u001b[38;5;124m'\u001b[39m, device_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# 'frontview', 'birdview', 'agentview', 'robot0_robotview', 'robot0_eye_in_hand')\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rs4tmr/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rs4tmr/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/anaconda3/envs/rs4tmr/lib/python3.9/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m/research/rs4tmr/robosuite/wrappers/gym_wrapper.py:122\u001b[0m, in \u001b[0;36mGymWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    Extends vanilla step() function call to return flattened observation instead of normal OrderedDict.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m            - (dict) misc information\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     ob_dict, reward, terminated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_obs(ob_dict), reward, terminated, \u001b[38;5;28;01mFalse\u001b[39;00m, info\n",
      "File \u001b[0;32m/research/rs4tmr/robosuite/environments/base.py:417\u001b[0m, in \u001b[0;36mMujocoEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Note: this is done all at once to avoid floating point inaccuracies\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol_timestep\n\u001b[0;32m--> 417\u001b[0m reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmujoco\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/research/rs4tmr/robosuite/environments/base.py:446\u001b[0m, in \u001b[0;36mMujocoEnv._post_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    436\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    Do any housekeeping after taking an action.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m            - (dict) empty dict to be filled with information by subclassed method\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreward\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# done if number of elapsed timesteps is greater than horizon\u001b[39;00m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimestep \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhorizon) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_done\n",
      "File \u001b[0;32m/research/rs4tmr/robosuite/environments/manipulation/tmr_pp.py:293\u001b[0m, in \u001b[0;36mTmrPickPlace.reward\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    291\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucess\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 293\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msucess\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m reward \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects_in_bins)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# add in shaped rewards\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rs4tmr/lib/python3.9/site-packages/wandb/sdk/lib/preinit.py:36\u001b[0m, in \u001b[0;36mPreInitCallable.<locals>.preinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreinit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from my_utils import init_env\n",
    "\n",
    "#from my_utils import make_env\n",
    "import mediapy as media\n",
    "\n",
    "\n",
    "env_id = 'TmrPickPlaceCan'\n",
    "horizon = 1000\n",
    "frames = []\n",
    "\n",
    "print('making env')\n",
    "vec_env = DummyVecEnv([init_env])\n",
    "\n",
    "print('load model')\n",
    "model = SAC.load(env_id, env=vec_env)\n",
    "\n",
    "print('reset env')\n",
    "obs = vec_env.reset()\n",
    "\n",
    "print('_observables: ')\n",
    "for key, val in vec_env.envs[0].env.env._observables.items():\n",
    "    print(key, val)\n",
    "    pass\n",
    "for t in range(horizon):\n",
    "    #print('predict by model')\n",
    "    action, _states = model.predict(obs)\n",
    "\n",
    "    #print('step forward')\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    #print(t, len(obs), obs)\n",
    "    \n",
    "    #print('rendering env')\n",
    "    rendered_array=vec_env.envs[0].sim.render(width=640, height=480, camera_name='frontview', device_id=0) # 'frontview', 'birdview', 'agentview', 'robot0_robotview', 'robot0_eye_in_hand')\n",
    "    # revese the image with respect to x-axis\n",
    "    rendered_array = rendered_array[::-1, :, :]\n",
    "    \n",
    "    frames.append(rendered_array)\n",
    "media.show_video(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 51)\n"
     ]
    }
   ],
   "source": [
    "obs = vec_env.reset()\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /research/rs4tmr/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robosuite environment maked: <class 'robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan'> <robosuite.environments.manipulation.tmr_pp.TmrPickPlaceCan object at 0x7ff04aaedeb0> ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_action_dim', '_check_grasp', '_check_robot_configuration', '_check_success', '_construct_objects', '_construct_visual_objects', '_create_camera_sensors', '_create_obj_sensors', '_create_segementation_sensor', '_destroy_sim', '_destroy_viewer', '_eef_xmat', '_eef_xpos', '_eef_xquat', '_get_observations', '_get_placement_initializer', '_gripper_to_target', '_initialize_sim', '_input2list', '_load_model', '_load_robots', '_obs_cache', '_observables', '_post_action', '_pre_action', '_reset_internal', '_setup_observables', '_setup_references', '_update_observables', '_visualizations', '_visualize_gripper_to_target', '_xml_processor', 'action_dim', 'action_spec', 'active_observables', 'add_observable', 'bin1_pos', 'bin2_pos', 'bin_size', 'camera_depths', 'camera_heights', 'camera_names', 'camera_segmentations', 'camera_widths', 'check_contact', 'clear_objects', 'close', 'close_renderer', 'control_freq', 'control_timestep', 'cur_time', 'deterministic_reset', 'done', 'edit_model_xml', 'enabled_observables', 'env_configuration', 'get_contacts', 'get_pixel_obs', 'hard_reset', 'has_offscreen_renderer', 'has_renderer', 'horizon', 'ignore_done', 'initialize_renderer', 'initialize_time', 'model', 'model_timestep', 'modify_observable', 'not_in_bin', 'num_cameras', 'num_robots', 'obj_body_id', 'obj_geom_id', 'obj_names', 'obj_to_use', 'object_id', 'object_id_to_sensors', 'object_to_id', 'objects', 'objects_in_bins', 'observation_modalities', 'observation_names', 'observation_spec', 'placement_initializer', 'render', 'render_camera', 'render_collision_mesh', 'render_gpu_device_id', 'render_visual_mesh', 'renderer', 'renderer_config', 'reset', 'reset_from_xml_string', 'reward', 'reward_scale', 'reward_shaping', 'robot_configs', 'robot_names', 'robots', 'set_camera_pos_quat', 'set_xml_processor', 'sim', 'sim_state_initial', 'single_object_mode', 'staged_rewards', 'step', 'table_friction', 'table_full_size', 'target_bin_placements', 'timestep', 'use_camera_obs', 'use_object_obs', 'viewer', 'viewer_get_obs', 'visual_objects', 'visualize', 'z_offset', 'z_rotation']\n",
      "27\n",
      "odict_keys(['robot0_joint_pos', 'robot0_joint_pos_cos', 'robot0_joint_pos_sin', 'robot0_joint_vel', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_eef_vel_lin', 'robot0_eef_vel_ang', 'robot0_gripper_qpos', 'robot0_gripper_qvel', 'world_pose_in_gripper', 'Milk_pos', 'Milk_quat', 'Milk_to_robot0_eef_pos', 'Milk_to_robot0_eef_quat', 'Bread_pos', 'Bread_quat', 'Bread_to_robot0_eef_pos', 'Bread_to_robot0_eef_quat', 'Cereal_pos', 'Cereal_quat', 'Cereal_to_robot0_eef_pos', 'Cereal_to_robot0_eef_quat', 'Can_pos', 'Can_quat', 'Can_to_robot0_eef_pos', 'Can_to_robot0_eef_quat'])\n"
     ]
    }
   ],
   "source": [
    "import robosuite as suite\n",
    "from robosuite.wrappers import GymWrapper\n",
    "\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "\n",
    "rsenv = suite.make(\n",
    "    \"TmrPickPlaceCan\",\n",
    "    robots=\"UR5e\",  # use UR5e robot\n",
    "    use_camera_obs=False,  # use pixel observations\n",
    "    has_offscreen_renderer=True,  # needed if using pixel obs\n",
    "    has_renderer=True,  # make sure we can render to the screen\n",
    "    reward_shaping=True,  # use dense rewards\n",
    "    control_freq=20,  # control should happen fast enough so that simulation looks smooth\n",
    ")\n",
    "\n",
    "# full_observable_list = [\n",
    "#     'robot0_joint_pos', \n",
    "#     'robot0_joint_pos_cos', \n",
    "#     'robot0_joint_pos_sin', \n",
    "#     'robot0_joint_vel', \n",
    "#     'robot0_eef_pos', \n",
    "#     'robot0_eef_quat', \n",
    "#     'robot0_eef_vel_lin', \n",
    "#     'robot0_eef_vel_ang', \n",
    "#     'robot0_gripper_qpos', \n",
    "#     'robot0_gripper_qvel', \n",
    "#     'agentview_image', \n",
    "#     'world_pose_in_gripper', \n",
    "#     'Milk_pos', \n",
    "#     'Milk_quat', \n",
    "#     'Milk_to_robot0_eef_pos', \n",
    "#     'Milk_to_robot0_eef_quat', \n",
    "#     'Bread_pos', \n",
    "#     'Bread_quat', \n",
    "#     'Bread_to_robot0_eef_pos', \n",
    "#     'Bread_to_robot0_eef_quat', \n",
    "#     'Cereal_pos', \n",
    "#     'Cereal_quat', \n",
    "#     'Cereal_to_robot0_eef_pos', \n",
    "#     'Cereal_to_robot0_eef_quat', \n",
    "#     'Can_pos', \n",
    "#     'Can_quat', \n",
    "#     'Can_to_robot0_eef_pos', \n",
    "#     'Can_to_robot0_eef_quat',\n",
    "# ]\n",
    "# for observable in full_observable_list:\n",
    "#     rsenv.modify_observable(observable, 'enabled', True)\n",
    "#     rsenv.modify_observable(observable, 'active', True)\n",
    "\n",
    "useless_observable_list = [\n",
    "    # 'robot0_joint_pos', \n",
    "    # 'robot0_joint_pos_cos', \n",
    "    # 'robot0_joint_pos_sin', \n",
    "    # 'robot0_joint_vel', \n",
    "    # 'robot0_eef_pos', \n",
    "    # 'robot0_eef_quat', \n",
    "    # 'robot0_eef_vel_lin', \n",
    "    # 'robot0_eef_vel_ang', \n",
    "    # 'robot0_gripper_qpos', \n",
    "    # 'robot0_gripper_qvel', \n",
    "    # 'agentview_image', \n",
    "    # 'world_pose_in_gripper', \n",
    "    # 'Milk_pos', \n",
    "    # 'Milk_quat', \n",
    "    # 'Milk_to_robot0_eef_pos', \n",
    "    # 'Milk_to_robot0_eef_quat', \n",
    "    # 'Bread_pos', \n",
    "    # 'Bread_quat', \n",
    "    # 'Bread_to_robot0_eef_pos', \n",
    "    # 'Bread_to_robot0_eef_quat', \n",
    "    # 'Cereal_pos', \n",
    "    # 'Cereal_quat', \n",
    "    # 'Cereal_to_robot0_eef_pos', \n",
    "    # 'Cereal_to_robot0_eef_quat', \n",
    "    # 'Can_pos', \n",
    "    # 'Can_quat', \n",
    "    # 'Can_to_robot0_eef_pos', \n",
    "    # 'Can_to_robot0_eef_quat',\n",
    "]\n",
    "for observable in useless_observable_list:\n",
    "    rsenv.modify_observable(observable, 'enabled', False)\n",
    "    rsenv.modify_observable(observable, 'active', False)\n",
    "\n",
    "print('Robosuite environment maked:',type(rsenv) , rsenv, dir(rsenv))\n",
    "print(len(rsenv._observables.keys()))\n",
    "print(rsenv._observables.keys())\n",
    "\n",
    "env = GymWrapper(\n",
    "    rsenv\n",
    ")\n",
    "\n",
    "env.reset(seed=0)\n",
    "\n",
    "new_env = Monitor(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[164, 155, 147],\n",
       "        [162, 153, 145],\n",
       "        [163, 154, 146],\n",
       "        ...,\n",
       "        [179, 170, 163],\n",
       "        [163, 154, 146],\n",
       "        [181, 172, 164]],\n",
       "\n",
       "       [[165, 156, 149],\n",
       "        [163, 154, 146],\n",
       "        [162, 153, 145],\n",
       "        ...,\n",
       "        [163, 155, 146],\n",
       "        [177, 169, 160],\n",
       "        [197, 188, 179]],\n",
       "\n",
       "       [[167, 158, 151],\n",
       "        [165, 156, 148],\n",
       "        [163, 154, 146],\n",
       "        ...,\n",
       "        [185, 177, 168],\n",
       "        [192, 183, 174],\n",
       "        [189, 180, 171]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[129, 127, 123],\n",
       "        [129, 127, 123],\n",
       "        [129, 128, 124],\n",
       "        ...,\n",
       "        [ 86,  85,  82],\n",
       "        [ 85,  84,  82],\n",
       "        [ 86,  84,  82]],\n",
       "\n",
       "       [[129, 128, 124],\n",
       "        [129, 127, 123],\n",
       "        [128, 127, 122],\n",
       "        ...,\n",
       "        [ 85,  84,  81],\n",
       "        [ 85,  84,  81],\n",
       "        [ 86,  85,  82]],\n",
       "\n",
       "       [[128, 126, 121],\n",
       "        [128, 125, 120],\n",
       "        [127, 124, 120],\n",
       "        ...,\n",
       "        [ 84,  82,  79],\n",
       "        [ 85,  83,  80],\n",
       "        [ 85,  84,  81]]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsenv = suite.make(\n",
    "    \"TmrPickPlaceCan\",\n",
    "    robots=\"UR5e\",  # use UR5e robot\n",
    "    use_camera_obs=False,  # use pixel observations\n",
    "    has_offscreen_renderer=True,  # needed if using pixel obs\n",
    "    has_renderer=True,  # make sure we can render to the screen\n",
    "    reward_shaping=True,  # use dense rewards\n",
    "    control_freq=20,  # control should happen fast enough so that simulation looks smooth\n",
    ")\n",
    "rsenv.sim.render(width=640, height=480, camera_name='frontview', device_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(new_env.render())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs4tmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
