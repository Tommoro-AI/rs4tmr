{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "# 필요한 클래스 및 함수 임포트\n",
    "from cleanrl.cleanrl.ppo_continuous_action import  load_ppo_checkpoint\n",
    "import cv2\n",
    "\n",
    "def load_model_and_rollout(model_path, task_id=\"HalfCheetah-v4\", num_episodes=10, seed=1, gamma=0.99, control_mode='OSC_POSITION'):\n",
    "    \"\"\"\n",
    "    저장된 모델을 불러와 환경에서 평가를 수행하는 함수\n",
    "    \"\"\"\n",
    "    visualize = True\n",
    "    frames = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    env, agent = load_ppo_checkpoint(checkpoint_path=model_path, \n",
    "                                     task_id=task_id, \n",
    "                                     control_mode=control_mode,\n",
    "                                     seed=seed, \n",
    "                                     \n",
    "                                     gamma=gamma, active_image=True)\n",
    "    rollout_horizon = 200\n",
    "\n",
    "    # 평가 수행\n",
    "    total_rewards = []\n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        obs = torch.Tensor(obs).to(device)\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        \n",
    "        image_frame = env.envs[0].image_states['agentview_image']\n",
    "        image_frame = np.array(image_frame[::-1, :, :], dtype=np.uint8)  # 명시적으로 numpy 배열로 변환\n",
    "        frames.append(image_frame)\n",
    "        # convert image_frame cv2 image\n",
    "        image_frame = cv2.cvtColor(image_frame, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "        for i in range(rollout_horizon):\n",
    "            with torch.no_grad():\n",
    "                obs = torch.Tensor(obs).to(device)\n",
    "                action, _, _, _ = agent.get_action_and_value(obs)\n",
    "            obs, reward, terminations, truncations, info = env.step(action.cpu().numpy())\n",
    "            #print(f\"reward: {reward}, terminations: {terminations}, truncations: {truncations}, infos: {infos}\")\n",
    "            done = np.logical_or(terminations, truncations).any()\n",
    "            episode_reward += reward[0]  # 첫 번째 환경의 보상 합산\n",
    "            \n",
    "            # 새로운 프레임 가져오기 및 변환\n",
    "            image_frame = env.envs[0].image_states['agentview_image']\n",
    "            image_frame = np.array(image_frame[::-1, :, :], dtype=np.uint8)  # numpy 배열로 변환\n",
    "\n",
    "            #image_frame = cv2.cvtColor(image_frame, cv2.COLOR_RGB2BGR)\n",
    "            # draw text on image_frame episode reward, reward, small text\n",
    "            cv2.putText(image_frame, f\"Episode Reward: {episode_reward:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(image_frame, f\"Reward: {reward[0]:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            #print(env.envs[0].check_success())\n",
    "            # sucess\n",
    "            if env.envs[0].is_success:\n",
    "                cv2.putText(image_frame, \"Success\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                env.reset()\n",
    "            frames.append(image_frame)\n",
    "            \n",
    "            \n",
    "        print(f\"Episode {episode + 1}: Total Reward: {episode_reward}\")\n",
    "        total_rewards.append(episode_reward)\n",
    "\n",
    "    env.close()\n",
    "    # 평균 리턴 출력\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    print(f\"Average Reward over {num_episodes} episodes: {avg_reward}\")\n",
    "    \n",
    "    media.show_video(frames, fps=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### controller_config: OSC_POSITION ###\n",
      "control_freq: 20\n",
      "ignore_done: False\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델 불러와 평가하기\n",
    "#model_path = \"/research/rs4tmr/cleanrl/cleanrl/runs/tr__ppo_continuous_action__s1__2024-09-26_05-11-00/ppo_continuous_action_380928.cleanrl_model\"\n",
    "model_path = \"runs/lift_ppo_long_learning_s1__2024-10-02 21_37_45/ppo_continuous_action_4800512\"#.cleanrl_model\"  # 모델 경로 지정\n",
    "load_model_and_rollout(model_path, task_id=\"lift\", num_episodes=1, control_mode=\"OSC_POSITION\")  # 모델 불러와 평가 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_env: task_id: lift\n",
      "### controller_config: OSC_POSE ###\n",
      "control_freq: 20\n",
      "ignore_done: False\n",
      "########################\n",
      "### Observation keys ###\n",
      "Key: robot0_eef_pos, size: 3\n",
      "Key: robot0_eef_quat, size: 4\n",
      "Key: robot0_eef_vel_lin, size: 3\n",
      "Key: robot0_eef_vel_ang, size: 3\n",
      "Key: robot0_gripper_qpos, size: 6\n",
      "Key: robot0_gripper_qvel, size: 6\n",
      "Key: gripper_to_cube_pos, size: 3\n",
      "Key: robot0_proprio-state, size: 25\n",
      "Key: object-state, size: 3\n",
      "Total observation size: 56\n",
      "########################\n",
      "####### Options ########\n",
      "task_id: lift\n",
      "active_rewards: rghl\n",
      "control_mode: OSC_POSE\n",
      "reward_shaping: True\n",
      "fix_object: False\n",
      "active_image: False\n",
      "wandb_enabled: False\n",
      "########################\n",
      "Using CUDA\n",
      "Episode 1: Total Reward: 2.9907518002453233, Success: False, 199 step\n",
      "Episode 2: Total Reward: 9.333626540836358, Success: False, 199 step\n",
      "Episode 3: Total Reward: 7.33703670896344, Success: False, 199 step\n",
      "Episode 4: Total Reward: 3.2029788842764746, Success: True, 142 step\n",
      "Episode 5: Total Reward: 2.6847744091490617, Success: False, 199 step\n",
      "Episode 6: Total Reward: 2.8187903432026546, Success: False, 199 step\n",
      "Episode 7: Total Reward: 6.156033431185024, Success: False, 199 step\n",
      "Episode 8: Total Reward: 5.27962091168704, Success: False, 199 step\n",
      "Episode 9: Total Reward: 5.288897248828156, Success: False, 199 step\n",
      "Episode 10: Total Reward: 1.7675482072758881, Success: True, 88 step\n",
      "Episode 11: Total Reward: 6.280526176854945, Success: False, 199 step\n",
      "Episode 12: Total Reward: 7.936319907856283, Success: False, 199 step\n",
      "Episode 13: Total Reward: 7.296765203878889, Success: False, 199 step\n",
      "Episode 14: Total Reward: 4.552029031044603, Success: False, 199 step\n",
      "Episode 15: Total Reward: 4.0469070819679915, Success: False, 199 step\n",
      "Episode 16: Total Reward: 3.9419289187761843, Success: False, 199 step\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "# 필요한 클래스 및 함수 임포트\n",
    "from cleanrl.cleanrl.ppo_continuous_action import  load_model_and_evaluate\n",
    "import cv2\n",
    "import warnings\n",
    "import wandb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "model_path = \"runs/lift_ppo_long_learning,OSC_POSE_s1__2024-10-02 21_48_32/ppo_continuous_action_4800512\"#.cleanrl_model\"  # 모델 경로 지정\n",
    "load_model_and_evaluate(model_path=model_path, task_id=\"lift\", num_episodes=50, verbose=True, control_mode='OSC_POSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs4tmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
