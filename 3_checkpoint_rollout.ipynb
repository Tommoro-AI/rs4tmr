{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /research/rs4tmr/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "# 필요한 클래스 및 함수 임포트\n",
    "from cleanrl.cleanrl.ppo_continuous_action import  load_ppo_checkpoint\n",
    "import cv2\n",
    "\n",
    "def load_model_and_rollout(model_path, task_id=\"HalfCheetah-v4\", num_episodes=10, \n",
    "                           seed=1, gamma=0.99, control_mode='OSC_POSITION',\n",
    "                            picking_success=False,\n",
    "                            ):\n",
    "    \"\"\"\n",
    "    저장된 모델을 불러와 환경에서 평가를 수행하는 함수\n",
    "    \"\"\"\n",
    "    visualize = True\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    env, agent = load_ppo_checkpoint(checkpoint_path=model_path, \n",
    "                                     task_id=task_id, \n",
    "                                     control_mode=control_mode,\n",
    "                                     seed=seed, \n",
    "                                     \n",
    "                                     gamma=gamma, active_image=True,\n",
    "                                     )\n",
    "    rollout_horizon = 200\n",
    "    #agent.eval()\n",
    "    # 평가 수행\n",
    "    total_rewards = []\n",
    "    \n",
    "    \n",
    "    frames = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        obs = torch.Tensor(obs).to(device)\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        \n",
    "        image_frame = env.envs[0].image_states['agentview_image']\n",
    "        image_frame = np.array(image_frame[::-1, :, :], dtype=np.uint8)  # 명시적으로 numpy 배열로 변환\n",
    "        episode_frames = []\n",
    "        \n",
    "        episode_frames.append(image_frame)\n",
    "        #episode_frames = cv2.cvtColor(image_frame, cv2.COLOR_RGB2BGR)        \n",
    "        for i in range(rollout_horizon):\n",
    "            with torch.no_grad():\n",
    "                obs = torch.Tensor(obs).to(device)\n",
    "                action, _, _, _ = agent.get_action_and_value(obs)\n",
    "            obs, reward, terminations, truncations, info = env.step(action.cpu().numpy())\n",
    "            #print(f\"reward: {reward}, terminations: {terminations}, truncations: {truncations}, infos: {infos}\")\n",
    "            done = np.logical_or(terminations, truncations).any()\n",
    "            episode_reward += reward[0]  # 첫 번째 환경의 보상 합산\n",
    "\n",
    "            # Proceess image frame            \n",
    "            # 새로운 프레임 가져오기 및 변환\n",
    "            image_frame = env.envs[0].image_states['agentview_image']\n",
    "            image_frame = np.array(image_frame[::-1, :, :], dtype=np.uint8)  # numpy 배열로 변환\n",
    "            cv2.putText(image_frame, f\"Episode Reward: {episode_reward:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(image_frame, f\"Reward: {reward[0]:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "            if env.envs[0].is_success:\n",
    "                cv2.putText(image_frame, \"Success\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            episode_frames.append(image_frame)\n",
    "    \n",
    "            \n",
    "            # check last frame\n",
    "            if (i == rollout_horizon - 1) or env.envs[0].is_success:\n",
    "                if not picking_success :\n",
    "                    frames += episode_frames\n",
    "                    break\n",
    "                else :\n",
    "                    if env.envs[0].is_success:\n",
    "                        frames += episode_frames\n",
    "                        print(\"Success, add frames\")\n",
    "                        break\n",
    "                    else :\n",
    "                        print(\"Fail, drop frames\")\n",
    "                        break\n",
    "                \n",
    "        print(f\"Episode {episode + 1}: Total Reward: {episode_reward}\")\n",
    "        total_rewards.append(episode_reward)\n",
    "\n",
    "    env.close()\n",
    "    # 평균 리턴 출력\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    print(f\"Average Reward over {num_episodes} episodes: {avg_reward}\")\n",
    "    if len(frames) > 0:\n",
    "        media.show_video(frames, fps=30)\n",
    "    else :\n",
    "        print(\"No frames to show\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### controller_config: OSC_POSITION ###\n",
      "#### J PickPlace ####\n",
      "fix_object:False\n",
      "control_freq: 20\n",
      "ignore_done: False\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/research/rs4tmr/cleanrl/cleanrl/runs/pickplace_ppo_tmrpp_test_s43412__2024-10-04 17:59:54/ppo_continuous_action_best.cleanrl_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 저장된 모델 불러와 평가하기\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model_path = \"/research/rs4tmr/cleanrl/cleanrl/runs/tr__ppo_continuous_action__s1__2024-09-26_05-11-00/ppo_continuous_action_380928.cleanrl_model\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/pickplace_ppo_tmrpp_test_s43412__2024-10-04 17:59:54/ppo_continuous_action_best\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;66;03m#.cleanrl_model\"  # 모델 경로 지정\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mload_model_and_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpickplace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOSC_POSITION\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicking_success\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 모델 불러와 평가 수행\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mload_model_and_rollout\u001b[0;34m(model_path, task_id, num_episodes, seed, gamma, control_mode, picking_success)\u001b[0m\n\u001b[1;32m     16\u001b[0m visualize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m env, agent \u001b[38;5;241m=\u001b[39m \u001b[43mload_ppo_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcontrol_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                 \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m rollout_horizon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#agent.eval()\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 평가 수행\u001b[39;00m\n",
      "File \u001b[0;32m/research/rs4tmr/cleanrl/cleanrl/ppo_continuous_action.py:240\u001b[0m, in \u001b[0;36mload_ppo_checkpoint\u001b[0;34m(checkpoint_path, task_id, iota, seed, control_mode, gamma, control_freq, active_image, verbose, ignore_done)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Agent 초기화 및 모델 불러오기\u001b[39;00m\n\u001b[1;32m    239\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent(env)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 240\u001b[0m agent\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    241\u001b[0m agent\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# 평가 모드로 전환\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# 환경 생성 후\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rs4tmr/lib/python3.9/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/rs4tmr/lib/python3.9/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/rs4tmr/lib/python3.9/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/research/rs4tmr/cleanrl/cleanrl/runs/pickplace_ppo_tmrpp_test_s43412__2024-10-04 17:59:54/ppo_continuous_action_best.cleanrl_model'"
     ]
    }
   ],
   "source": [
    "# 저장된 모델 불러와 평가하기\n",
    "#model_path = \"/research/rs4tmr/cleanrl/cleanrl/runs/tr__ppo_continuous_action__s1__2024-09-26_05-11-00/ppo_continuous_action_380928.cleanrl_model\"\n",
    "model_path = \"runs/pickplace_ppo_tmrpp_test_s43412__2024-10-04 17:59:54/ppo_continuous_action_251904\"#.cleanrl_model\"  # 모델 경로 지정\n",
    "load_model_and_rollout(model_path, task_id=\"pickplace\", num_episodes=1, control_mode=\"OSC_POSITION\", picking_success = False)  # 모델 불러와 평가 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_env: task_id: lift\n",
      "### controller_config: OSC_POSE ###\n",
      "control_freq: 20\n",
      "ignore_done: False\n",
      "########################\n",
      "### Observation keys ###\n",
      "Key: robot0_eef_pos, size: 3\n",
      "Key: robot0_eef_quat, size: 4\n",
      "Key: robot0_eef_vel_lin, size: 3\n",
      "Key: robot0_eef_vel_ang, size: 3\n",
      "Key: robot0_gripper_qpos, size: 6\n",
      "Key: robot0_gripper_qvel, size: 6\n",
      "Key: gripper_to_cube_pos, size: 3\n",
      "Key: robot0_proprio-state, size: 25\n",
      "Key: object-state, size: 3\n",
      "Total observation size: 56\n",
      "########################\n",
      "####### Options ########\n",
      "task_id: lift\n",
      "active_rewards: rghl\n",
      "control_mode: OSC_POSE\n",
      "reward_shaping: True\n",
      "fix_object: False\n",
      "active_image: False\n",
      "wandb_enabled: False\n",
      "########################\n",
      "Using CUDA\n",
      "Episode 1: Total Reward: 2.9907518002453233, Success: False, 199 step\n",
      "Episode 2: Total Reward: 9.333626540836358, Success: False, 199 step\n",
      "Episode 3: Total Reward: 7.33703670896344, Success: False, 199 step\n",
      "Episode 4: Total Reward: 3.2029788842764746, Success: True, 142 step\n",
      "Episode 5: Total Reward: 2.6847744091490617, Success: False, 199 step\n",
      "Episode 6: Total Reward: 2.8187903432026546, Success: False, 199 step\n",
      "Episode 7: Total Reward: 6.156033431185024, Success: False, 199 step\n",
      "Episode 8: Total Reward: 5.27962091168704, Success: False, 199 step\n",
      "Episode 9: Total Reward: 5.288897248828156, Success: False, 199 step\n",
      "Episode 10: Total Reward: 1.7675482072758881, Success: True, 88 step\n",
      "Episode 11: Total Reward: 6.280526176854945, Success: False, 199 step\n",
      "Episode 12: Total Reward: 7.936319907856283, Success: False, 199 step\n",
      "Episode 13: Total Reward: 7.296765203878889, Success: False, 199 step\n",
      "Episode 14: Total Reward: 4.552029031044603, Success: False, 199 step\n",
      "Episode 15: Total Reward: 4.0469070819679915, Success: False, 199 step\n",
      "Episode 16: Total Reward: 3.9419289187761843, Success: False, 199 step\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "# 필요한 클래스 및 함수 임포트\n",
    "from cleanrl.cleanrl.ppo_continuous_action import  load_model_and_evaluate\n",
    "import cv2\n",
    "import warnings\n",
    "import wandb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "model_path = \"runs/lift_ppo_long_learning,OSC_POSE_s1__2024-10-02 21_48_32/ppo_continuous_action_4800512\"#.cleanrl_model\"  # 모델 경로 지정\n",
    "load_model_and_evaluate(model_path=model_path, task_id=\"lift\", num_episodes=50, verbose=True, control_mode='OSC_POSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs4tmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
